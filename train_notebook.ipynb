{"cells":[{"cell_type":"markdown","metadata":{"id":"yYryuRDeqbxK"},"source":["# **Cultura e Pr√°ticas em DataOps e MLOps**\n","**Autor**: Renan Santos Mendes\n","\n","**Email**: renansantosmendes@gmail.com\n","\n","**Descri√ß√£o**: Este notebook apresenta um exemplo de uma rede neural profunda com mais de uma camada para um problema de classifica√ß√£o.\n","\n","\n","# **Sa√∫de Fetal**\n","\n","As Cardiotocografias (CTGs) s√£o op√ß√µes simples e de baixo custo para avaliar a sa√∫de fetal, permitindo que os profissionais de sa√∫de atuem na preven√ß√£o da mortalidade infantil e materna. O pr√≥prio equipamento funciona enviando pulsos de ultrassom e lendo sua resposta, lan√ßando luz sobre a frequ√™ncia card√≠aca fetal (FCF), movimentos fetais, contra√ß√µes uterinas e muito mais.\n","\n","Este conjunto de dados cont√©m 2126 registros de caracter√≠sticas extra√≠das de exames de Cardiotocografias, que foram ent√£o classificados por tr√™s obstetras especialistas em 3 classes:\n","\n","- Normal\n","- Suspeito\n","- Patol√≥gico"]},{"cell_type":"markdown","metadata":{"id":"MkB47-my-kq9"},"source":["# Instalando pacotes"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.34.0 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n","Collecting tensorflow-intel==2.17.0\n","  Using cached tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n","Collecting ml-dtypes<0.5.0,>=0.3.1\n","  Using cached ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n","Collecting absl-py>=1.0.0\n","  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n","Collecting h5py>=3.10.0\n","  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n","Collecting libclang>=13.0.0\n","  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n","Requirement already satisfied: setuptools in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (61.2.0)\n","Collecting keras>=3.2.0\n","  Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n","Requirement already satisfied: packaging in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (21.3)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Using cached protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n","Collecting termcolor>=1.1.0\n","  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Collecting opt-einsum>=2.3.2\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.12.1)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n","  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n","Collecting google-pasta>=0.1.1\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.42.0)\n","Collecting flatbuffers>=24.3.25\n","  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n","Collecting astunparse>=1.6.0\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting tensorboard<2.18,>=2.17\n","  Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.37.1)\n","Collecting namex\n","  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree\n","  Using cached optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n","Requirement already satisfied: rich in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.0.3)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.3.4)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Using cached grpcio-1.66.0-cp39-cp39-win_amd64.whl (4.3 MB)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\maxwe\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n","Installing collected packages: tensorboard-data-server, protobuf, optree, namex, ml-dtypes, h5py, grpcio, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.1\n","    Uninstalling protobuf-3.19.1:\n","      Successfully uninstalled protobuf-3.19.1\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.6.0\n","    Uninstalling h5py-3.6.0:\n","      Successfully uninstalled h5py-3.6.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.42.0\n","    Uninstalling grpcio-1.42.0:\n","      Successfully uninstalled grpcio-1.42.0\n","Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.0 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRE1wGJ9-jxZ"},"outputs":[],"source":["#!pip install mlflow==2.2.2 -q"]},{"cell_type":"markdown","metadata":{"id":"4WgsLeJngPb1"},"source":["# 1 - Importando os m√≥dulos necess√°rios"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\MAXWE\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","c:\\Users\\MAXWE\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n","  from pandas.core import (\n"]}],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"55YREGWfhXuu"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import random as python_random\n","import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, InputLayer\n","from keras.utils import to_categorical\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"NFTzaAkEr-IP"},"source":["# Definindo fun√ß√µes adicionais"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"OgKUlrlbozyR"},"outputs":[],"source":["def reset_seeds():\n","   os.environ['PYTHONHASHSEED']=str(42)\n","   tf.random.set_seed(42)\n","   np.random.seed(42)\n","   random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"I5uGdrdeh0QG"},"source":["# 2 - Fazendo a leitura do dataset e atribuindo √†s respectivas vari√°veis"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"95168wcThmD2"},"outputs":[],"source":["data = pd.read_csv('https://raw.githubusercontent.com/renansantosmendes/lectures-cdas-2023/master/fetal_health_reduced.csv')"]},{"cell_type":"markdown","metadata":{"id":"TEM30W0agQA_"},"source":["# Dando uma leve olhada nos dados"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HkQ-JIfWo3Wh"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>severe_decelerations</th>\n","      <th>accelerations</th>\n","      <th>fetal_movement</th>\n","      <th>uterine_contractions</th>\n","      <th>fetal_health</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   severe_decelerations  accelerations  fetal_movement  uterine_contractions  \\\n","0                   0.0            0.0             0.0                   0.0   \n","1                   0.0            6.0             0.0                   6.0   \n","2                   0.0            3.0             0.0                   8.0   \n","3                   0.0            3.0             0.0                   8.0   \n","4                   0.0            7.0             0.0                   8.0   \n","\n","   fetal_health  \n","0           2.0  \n","1           1.0  \n","2           1.0  \n","3           1.0  \n","4           1.0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"1eQEA-fzgQ0G"},"source":["# 3 - Preparando o dado antes de iniciar o treino do modelo"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jBK7SgPxh7YY"},"outputs":[],"source":["X=data.drop([\"fetal_health\"], axis=1)\n","y=data[\"fetal_health\"]\n","\n","columns_names = list(X.columns)\n","scaler = preprocessing.StandardScaler()\n","X_df = scaler.fit_transform(X)\n","X_df = pd.DataFrame(X_df, columns=columns_names)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_df,\n","                                                    y,\n","                                                    test_size=0.3,\n","                                                    random_state=42)\n","\n","y_train = y_train -1\n","y_test = y_test - 1"]},{"cell_type":"markdown","metadata":{"id":"54CmcOG1gRn9"},"source":["# 4 - Criando o modelo e adicionando as camadas"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4y2kKy_EkLGt"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\MAXWE\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n","  warnings.warn(\n"]}],"source":["reset_seeds()\n","model = Sequential()\n","model.add(InputLayer(input_shape=(X_train.shape[1], )))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(3, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"E0JmDrz6iQDw"},"source":["# 5 - Compilando o modelo\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"7IeY0b4i1gQj"},"outputs":[],"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9RlCNYss91nf"},"outputs":[],"source":["import mlflow\n","\n","os.environ['MLFLOW_TRACKING_USERNAME'] = 'renansantosmendes'\n","os.environ['MLFLOW_TRACKING_PASSWORD'] = '6d730ef4a90b1caf28fbb01e5748f0874fda6077'\n","mlflow.set_tracking_uri('https://dagshub.com/renansantosmendes/mlops-ead.mlflow')\n","\n","mlflow.tensorflow.autolog(log_models=True,\n","                          log_input_examples=True,\n","                          log_model_signatures=True)"]},{"cell_type":"markdown","metadata":{"id":"MoHbKkvCim-p"},"source":["# 6 - Executando o treino do modelo"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"w8IX2tHI2VX4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024/08/23 19:41:52 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31/50\n","Epoch 32/50\n","Epoch 33/50\n","Epoch 34/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35/50\n","Epoch 36/50\n","Epoch 37/50\n","Epoch 38/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39/50\n","Epoch 40/50\n","Epoch 41/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44/50\n","Epoch 45/50\n","Epoch 46/50\n","Epoch 47/50\n","Epoch 48/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49/50\n","Epoch 50/50\n"]},{"name":"stderr","output_type":"stream","text":["2024/08/23 19:43:08 WARNING mlflow.tensorflow: Failed to gather input example: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n","2024/08/23 19:43:08 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n","2024/08/23 19:43:08 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n","2024/08/23 19:43:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\MAXWE\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n","2024/08/23 19:43:25 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n","2024/08/23 19:43:27 INFO mlflow.tracking._tracking_service.client: üèÉ View run experiment_0mlops_ead at: https://dagshub.com/renansantosmendes/mlops-ead.mlflow/#/experiments/0/runs/72d45adf9d54434f863b9a799936286c.\n","2024/08/23 19:43:27 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/renansantosmendes/mlops-ead.mlflow/#/experiments/0.\n"]}],"source":["with mlflow.start_run(run_name='experiment_0mlops_ead') as run:\n","  model.fit(X_train,\n","            y_train,\n","            epochs=50,\n","            validation_split=0.2,\n","            verbose=3)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
